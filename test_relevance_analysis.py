#!/usr/bin/env python3
"""
æµ‹è¯•åœ°åŸŸç›¸å…³æ€§åˆ†æåŠŸèƒ½
"""

from services.news_service import NewsService
from services.ollama_service import OllamaService
from services.weather_service import WeatherService

def test_news_relevance_analysis():
    """æµ‹è¯•æ–°é—»åœ°åŸŸç›¸å…³æ€§åˆ†æ"""
    print("ğŸ§ª æµ‹è¯•æ–°é—»åœ°åŸŸç›¸å…³æ€§åˆ†æ...")
    
    news_service = NewsService()
    
    # è·å–æµ‹è¯•æ–°é—»æ•°æ®
    news_data = news_service.get_news(10)
    print(f"ğŸ“Š è·å–åˆ° {len(news_data)} æ¡æ–°é—»")
    
    # æµ‹è¯•ä¸åŒåŸå¸‚çš„ç›¸å…³æ€§åˆ†æ
    test_cities = ['åŒ—äº¬', 'ä¸Šæµ·', 'å¹¿å·', 'æ·±åœ³', 'æ­å·']
    
    for city in test_cities:
        print(f"\nğŸ™ï¸ æµ‹è¯•åŸå¸‚: {city}")
        
        # åˆ†æç›¸å…³æ€§
        relevance_analysis = news_service.analyze_news_relevance(news_data, city)
        
        print(f"   ç›¸å…³æ–°é—»æ•°é‡: {relevance_analysis['relevant_count']}/{relevance_analysis['total_count']}")
        print(f"   ç›¸å…³æ€§æ¯”ä¾‹: {relevance_analysis['relevance_rate']:.1%}")
        
        # æ˜¾ç¤ºç›¸å…³æ–°é—»æ ‡é¢˜
        if relevance_analysis['relevant_news']:
            print("   ç›¸å…³æ–°é—»:")
            for i, news in enumerate(relevance_analysis['relevant_news'][:3], 1):
                print(f"     {i}. {news['title']}")
        else:
            print("   æœªæ‰¾åˆ°ç›¸å…³æ–°é—»ï¼Œä½¿ç”¨å¤‡é€‰æ–°é—»")
            for i, news in enumerate(relevance_analysis['relevant_news'][:3], 1):
                print(f"     {i}. {news['title']}")

def test_city_keywords():
    """æµ‹è¯•åŸå¸‚å…³é”®è¯åŒ¹é…"""
    print("\nğŸ” æµ‹è¯•åŸå¸‚å…³é”®è¯åŒ¹é…...")
    
    news_service = NewsService()
    
    # æµ‹è¯•æ–°é—»
    test_news = [
        {
            'title': 'åŒ—äº¬ç§‘æŠ€åˆ›æ–°ä¸­å¿ƒå»ºè®¾åŠ é€Ÿæ¨è¿›',
            'summary': 'åŒ—äº¬ä½œä¸ºå…¨å›½ç§‘æŠ€åˆ›æ–°ä¸­å¿ƒï¼Œæ­£åœ¨åŠ é€Ÿæ¨è¿›å„é¡¹åˆ›æ–°é¡¹ç›®ã€‚'
        },
        {
            'title': 'ä¸Šæµ·è‡ªè´¸åŒºæ·±åŒ–æ”¹é©ï¼Œè¥å•†ç¯å¢ƒæŒç»­ä¼˜åŒ–',
            'summary': 'ä¸Šæµ·è‡ªè´¸åŒºæ·±åŒ–æ”¹é©æªæ–½ä¸æ–­ï¼Œè¥å•†ç¯å¢ƒæŒç»­ä¼˜åŒ–ã€‚'
        },
        {
            'title': 'å¹¿å·æ•°å­—ç»æµè“¬å‹ƒå‘å±•ï¼Œæ™ºæ…§åŸå¸‚å»ºè®¾æé€Ÿ',
            'summary': 'å¹¿å·æ•°å­—ç»æµè“¬å‹ƒå‘å±•ï¼Œæ™ºæ…§åŸå¸‚å»ºè®¾å…¨é¢æé€Ÿã€‚'
        },
        {
            'title': 'äººå·¥æ™ºèƒ½æŠ€æœ¯å‘å±•è¿…é€Ÿï¼ŒChatGPTå¼•é¢†AIé©å‘½',
            'summary': 'äººå·¥æ™ºèƒ½æŠ€æœ¯åœ¨å…¨çƒèŒƒå›´å†…å¿«é€Ÿå‘å±•ï¼ŒChatGPTç­‰å¤§è¯­è¨€æ¨¡å‹å¼•é¢†AIé©å‘½ã€‚'
        }
    ]
    
    test_cities = ['åŒ—äº¬', 'ä¸Šæµ·', 'å¹¿å·']
    
    for city in test_cities:
        print(f"\nğŸ™ï¸ åŸå¸‚: {city}")
        relevance_analysis = news_service.analyze_news_relevance(test_news, city)
        
        print(f"   ç›¸å…³æ–°é—»æ•°é‡: {relevance_analysis['relevant_count']}")
        for news in relevance_analysis['relevant_news']:
            print(f"   â€¢ {news['title']}")

def test_ai_summary_with_relevance():
    """æµ‹è¯•AIæ±‡æ€»çš„åœ°åŸŸç›¸å…³æ€§åŠŸèƒ½"""
    print("\nğŸ¤– æµ‹è¯•AIæ±‡æ€»çš„åœ°åŸŸç›¸å…³æ€§åŠŸèƒ½...")
    
    weather_service = WeatherService()
    news_service = NewsService()
    ollama_service = OllamaService()
    
    test_cities = ['åŒ—äº¬', 'ä¸Šæµ·', 'å¹¿å·']
    
    for city in test_cities:
        print(f"\nğŸ™ï¸ æµ‹è¯•åŸå¸‚: {city}")
        
        try:
            # è·å–å¤©æ°”å’Œæ–°é—»æ•°æ®
            weather_data = weather_service.get_weather(city)
            news_data = news_service.get_news(10)
            
            # ç”ŸæˆAIæ±‡æ€»
            summary = ollama_service.generate_summary(weather_data, news_data, city)
            
            print(f"   å¤©æ°”: {weather_data['description']} {weather_data['temperature']}Â°C")
            print(f"   æ±‡æ€»é•¿åº¦: {len(summary)} å­—ç¬¦")
            
            # æ£€æŸ¥æ±‡æ€»ä¸­æ˜¯å¦åŒ…å«åŸå¸‚ç›¸å…³ä¿¡æ¯
            if city in summary:
                print(f"   âœ… æ±‡æ€»åŒ…å«åŸå¸‚ä¿¡æ¯: {city}")
            else:
                print(f"   âš ï¸ æ±‡æ€»æœªæ˜ç¡®æåŠåŸå¸‚: {city}")
            
            # æ˜¾ç¤ºæ±‡æ€»çš„å‰å‡ è¡Œ
            lines = summary.split('\n')[:6]
            print("   æ±‡æ€»é¢„è§ˆ:")
            for line in lines:
                if line.strip():
                    print(f"     {line}")
            
        except Exception as e:
            print(f"   âŒ ç”Ÿæˆæ±‡æ€»å¤±è´¥: {e}")

def test_relevance_filtering():
    """æµ‹è¯•æ–°é—»ç­›é€‰åŠŸèƒ½"""
    print("\nğŸ”§ æµ‹è¯•æ–°é—»ç­›é€‰åŠŸèƒ½...")
    
    news_service = NewsService()
    
    # è·å–æ–°é—»æ•°æ®
    news_data = news_service.get_news(15)
    
    test_cities = ['åŒ—äº¬', 'ä¸Šæµ·', 'å¹¿å·', 'æ·±åœ³']
    
    for city in test_cities:
        print(f"\nğŸ™ï¸ åŸå¸‚: {city}")
        
        # ç­›é€‰ç›¸å…³æ–°é—»
        filtered_news = news_service.filter_news_by_city(news_data, city)
        
        print(f"   åŸå§‹æ–°é—»æ•°é‡: {len(news_data)}")
        print(f"   ç­›é€‰åæ•°é‡: {len(filtered_news)}")
        
        # æ˜¾ç¤ºç­›é€‰ç»“æœ
        for i, news in enumerate(filtered_news[:3], 1):
            print(f"   {i}. {news['title']}")

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸš€ åœ°åŸŸç›¸å…³æ€§åˆ†æåŠŸèƒ½æµ‹è¯•")
    print("=" * 50)
    
    # æµ‹è¯•æ–°é—»ç›¸å…³æ€§åˆ†æ
    test_news_relevance_analysis()
    
    # æµ‹è¯•åŸå¸‚å…³é”®è¯åŒ¹é…
    test_city_keywords()
    
    # æµ‹è¯•æ–°é—»ç­›é€‰åŠŸèƒ½
    test_relevance_filtering()
    
    # æµ‹è¯•AIæ±‡æ€»åŠŸèƒ½
    test_ai_summary_with_relevance()
    
    print("\nğŸ“Š æµ‹è¯•å®Œæˆï¼")
    print("=" * 50)
    print("âœ… åœ°åŸŸç›¸å…³æ€§åˆ†æåŠŸèƒ½å·²å®ç°")
    print("âœ… æ”¯æŒ20ä¸ªä¸»è¦åŸå¸‚çš„å…³é”®è¯åŒ¹é…")
    print("âœ… AIæ±‡æ€»ä¼šè‡ªåŠ¨ç­›é€‰ç›¸å…³æ–°é—»")
    print("âœ… æä¾›ç›¸å…³æ€§åˆ†æå’Œç»Ÿè®¡ä¿¡æ¯")

if __name__ == '__main__':
    main() 